defaults:
  - vmas_navigation_config
  - _self_



max_steps: 200
n_agents: 8
collisions: True  # 是否启用碰撞和激光雷达
agents_with_same_goal: 1  # 前多少个智能体共享同一目标,剩余的智能体目标独立,为1时所有智能体目标独立
split_goals: False  # 是否按队伍拆分目标（需要偶数智能体且各半队伍共用同一目标）
shared_rew: True  # 奖励是否在所有智能体间共享!!! TRUE收敛快
observe_all_goals: False  # 观测中是否包含所有目标的相对位置（True 时为异质/协作行为）
lidar_range: 0.35 #Lidar 最远探测距离（仅在启用碰撞时使用）
agent_radius: 0.1  # 智能体半径



#共享 shaping 奖励（shared_reward=True）：每步由第一个智能体计算全队奖励，把所有智能体的 shaping 变化（距离目标的势能下降量）相加后，同一个标量奖励分配给所有人。效果：鼓励整体朝各自目标前进，个体不直接区分贡献，团队协作导向。
#独立 shaping 奖励（shared_reward=False）：每个智能体单独计算自己距离目标的势能下降量作为奖励，彼此不影响。效果：各智能体只为自身到达目标负责，更偏个体主义。
#shaping 的含义：reward += (上一步势能 - 当前势能) * shaping_factor，势能这里是“到自身目标的距离 × shaping_factor”。距离减小（向目标靠近）时奖励为正，距离增大时为负。

#任务描述：随机生成的智能体需要导航至目标点。碰撞检测可以开启，智能体可以使用激光雷达来避免相互碰撞。奖励可以是共享的，也可以是个人获得的。除了位置、速度和激光雷达读数之外，
#每个智能体还可以被设置为仅观察其到目标点的相对距离，或者观察其到所有目标点的相对距离（在这种情况下，任务需要异构行为来解决）。场景也可以设置为多个智能体共享同一个目标。