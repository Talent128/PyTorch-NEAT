defaults:
  - vmas_passage_config
  - _self_

#环境固定智能体数量为5

max_steps: 1200
n_passages: 1         #需要留空的通道数量（不碰撞），决定可通过的缺口个数
shared_reward: True  # 是否共享奖励，True 时所有智能体共享同一奖励信号，False 时奖励



#共享 shaping 奖励（shared_reward=True）：每步由第一个智能体计算全队奖励，把所有智能体的 shaping 变化（距离目标的势能下降量）相加后，同一个标量奖励分配给所有人。效果：鼓励整体朝各自目标前进，个体不直接区分贡献，团队协作导向。
#独立 shaping 奖励（shared_reward=False）：每个智能体单独计算自己距离目标的势能下降量作为奖励，彼此不影响。效果：各智能体只为自身到达目标负责，更偏个体主义。
#shaping 的含义：reward += (上一步势能 - 当前势能) * shaping_factor，势能这里是“到自身目标的距离 × shaping_factor”。距离减小（向目标靠近）时奖励为正，距离增大时为负。